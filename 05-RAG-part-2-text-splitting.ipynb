{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6930004f",
   "metadata": {},
   "source": [
    "# Class Introduction\n",
    "\n",
    "## Objective\n",
    "Document splitting is often a crucial preprocessing step for many applications. It involves breaking down large texts into smaller, manageable chunks. This process offers several benefits, such as ensuring consistent processing of varying document lengths, overcoming input size limitations of models, and improving the quality of text representations used in retrieval systems. There are several strategies for splitting documents, each with its own advantages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bb5a0",
   "metadata": {},
   "source": [
    "**Relevant Links**\n",
    "- [HuggingFace chunk visualizer](https://huggingface.co/spaces/Nymbo/chunk_visualizer) \n",
    "- [5 Levels of text splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "- [RAG Course](https://www.youtube.com/watch?v=sVcwVQRHIc8)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6bf8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rogered1320/miniforge3/envs/llm-training/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from utils import *\n",
    "import os\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"llm-training-05-rag-p2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbf50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c5ceb",
   "metadata": {},
   "source": [
    "## Character Splitting\n",
    "\n",
    "Character splitting is the most basic form of splitting up your text. It is the process of simply dividing your text into N-character sized chunks regardless of their content or form.\n",
    "\n",
    "This method isn't recommended for any applications - but it's a great starting point for us to understand the basics.\n",
    "\n",
    "- **Pros:** Easy & Simple\n",
    "- **Cons:** Very rigid and doesn't take into account the structure of your text\n",
    "\n",
    "Concepts to know:\n",
    "\n",
    "- **Chunk Size** - The number of characters you would like in your chunks. 50, 100, 100,000, etc.\n",
    "- **Chunk Overlap** - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4e017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9414856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='This is the text I would like to chunk up. It is t'),\n",
       " Document(metadata={}, page_content='p. It is the example text for this exercise')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 50, chunk_overlap=10, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425d1a8",
   "metadata": {},
   "source": [
    "## Recursive Character Text Splitting\n",
    "\n",
    "Let's jump a level of complexity.\n",
    "\n",
    "The problem with Level #1 is that we don't take into account the structure of our document at all. We simply split by a fix number of characters.\n",
    "\n",
    "The Recursive Character Text Splitter helps with this. With it, we'll specify a series of separatators which will be used to split our docs.\n",
    "\n",
    "You can see the default separators for LangChain here. Let's take a look at them one by one.\n",
    "\n",
    "- \"\\n\\n\" - Double new line, or most commonly paragraph breaks\n",
    "- \"\\n\" - New lines\n",
    "- \" \" - Spaces\n",
    "- \"\" - Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a6f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text = \"\"\"\n",
    "One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
    "\n",
    "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
    "\n",
    "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c863aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\"),\n",
       " Document(metadata={}, page_content='Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor\\'s, you don\\'t get half as many customers. You get no customers, and you go out of business.'),\n",
       " Document(metadata={}, page_content=\"It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 450, chunk_overlap=0)\n",
    "text_splitter.create_documents([text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4b248",
   "metadata": {},
   "source": [
    "## Level 3: Document Specific Splitting <a id=\\\"DocumentSpecific\\\"></a>\n",
    "\n",
    "Stepping up our levels ladder, let's start to handle document types other than normal prose in a .txt. What if you have pictures? or a PDF? or code snippets?\n",
    "\n",
    "Our first two levels wouldn't work great for this so we'll need to find a different tactic.\n",
    "\n",
    "This level is all about making your chunking strategy fit your different data formats. Let's run through a bunch of examples of this in action\n",
    "\n",
    "The Markdown, Python, and JS splitters will basically be similar to Recursive Character, but with different separators.\n",
    "\n",
    "See all of LangChains document splitters [here](https://python.langchain.com/docs/how_to/code_splitter/)\n",
    "### Markdown\n",
    "\n",
    "You can see the separators [here](https://github.com/langchain-ai/langchain/blob/9ef2feb6747f5a69d186bd623b569ad722829a5e/libs/langchain/langchain/text_splitter.py#L1175).\n",
    "\n",
    "Separators:\n",
    "* `\\#{1,6}` - Split by new lines followed by a header (H1 through H6)\n",
    "* ```` ```\\ ```` - Code blocks\n",
    "* `\\\\\\\\\\*\\\\\\\\*\\\\\\\\*+\\` - Horizontal Lines\n",
    "* `\\---+\\` - Horizontal Lines\n",
    "* `\\___+\\` - Horizontal Lines\n",
    "* `\\\\` Double new lines\n",
    "* `\\` - New line\n",
    "* `\\\" \\\"` - Spaces\n",
    "* `\\\"\\\"` - Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecedc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596f27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='# Fun in California\\n\\n## Driving'),\n",
       " Document(metadata={}, page_content='Try driving on the 1 down to San Diego\\n\\n### Food'),\n",
       " Document(metadata={}, page_content=\"Make sure to eat a burrito while you're there\\n\\n## Hiking\"),\n",
       " Document(metadata={}, page_content='Go to Yosemite')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 60, chunk_overlap=0)\n",
    "splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c62253",
   "metadata": {},
   "source": [
    "## Agentic Chunking\n",
    "\n",
    "## Level 5: Agentic Chunking\n",
    "Can we instruct an LLM to do this task like a human would?\n",
    "\n",
    "How does a human even go about chunking in the first place?\n",
    "\n",
    "1. I would get myself a scratch piece of paper or notepad\n",
    "2. I'd start at the top of the essay and assume the first part will be a chunk (since we don't have any yet)\n",
    "3. Then I would keep going down the essay and evaluate if a new sentence or piece of the essay should be a part of the first chunk, if not, then create a new one\n",
    "4. Then keep doing that all the way down the essay until we got to the end.\n",
    "\n",
    "\n",
    "Example: `Greg went to the park. He likes walking` > `['Greg went to the park.', 'Greg likes walking']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688251ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1b9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic data class\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str]\n",
    "\n",
    "\n",
    "obj = hub.pull(\"wfh/proposal-indexing\")\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano').with_structured_output(Sentences)\n",
    "\n",
    "# use it in a runnable\n",
    "runnable = obj | llm\n",
    "\n",
    "# Then wrap it together in a function that'll return a list of propositions to us\n",
    "\n",
    "\n",
    "def get_propositions(text):\n",
    "    result = runnable.invoke({\n",
    "        \"input\": text\n",
    "    })\n",
    "    print(text)\n",
    "    print(result)  # Debugging: print the result to see its structure\n",
    "    print(\"==\" * 20)\n",
    "    # result is expected to be a dict with 'sentences' key\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454bbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources_rag/superlinear.txt') as file:\n",
    "    essay = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f64e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "sentences=[\"One of the most important things the speaker didn't understand about the world when the speaker was a child is the degree to which the returns for performance are superlinear.\", 'The speaker is referencing their childhood.', \"The speaker's childhood was a time when the speaker did not understand this particular concept.\", 'The concept involves the relationship between performance and returns.', 'The returns for performance are superlinear, meaning they increase more than proportionally as performance improves.']\n",
      "========================================\n",
      "Done with 0\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "sentences=['Teachers and coaches implicitly told us that the returns were linear.', \"Teachers and coaches told us 'You get out, what you put in.' in an implicit manner.\", \"I heard a thousand times the phrase 'You get out, what you put in.' from teachers and coaches.\", 'Teachers and coaches meant well when they told us about the returns.', 'The statement about the returns being linear is rarely true.', \"If a product is only half as good as a competitor's product, then the number of customers it receives is not half.\", \"A product that is only half as good as a competitor's product does not get half as many customers.\", \"A product that is only half as good as a competitor's product gets no customers.\", 'A product that gets no customers results in the business going out of business.']\n",
      "========================================\n",
      "Done with 1\n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
      "sentences=[\"It's obviously true that the returns for performance are superlinear in business.\", 'Some people think that this is a flaw of capitalism.', 'Some people think that if the rules of capitalism were changed, the superlinear returns for performance would stop being true.', 'Superlinear returns for performance are a feature of the world.', 'Superlinear returns for performance are not an artifact of rules we have invented.', 'The same pattern of superlinear returns is observed in fame.', 'The same pattern of superlinear returns is observed in power.', 'The same pattern of superlinear returns is observed in military victories.', 'The same pattern of superlinear returns is observed in knowledge.', 'The same pattern of superlinear returns is observed in benefits to humanity.', 'In all of these cases, the wealthy accumulate more wealth or benefits.']\n",
      "========================================\n",
      "Done with 2\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "sentences=['Understanding the concept of superlinear returns is essential to understanding the world.', 'If a person is ambitious, they should understand the concept of superlinear returns.', 'Understanding the concept of superlinear returns is important because it will be the wave that a person can surf on.']\n",
      "========================================\n",
      "Done with 3\n",
      "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "sentences=['It may seem as if there are a lot of different situations with superlinear returns.', 'There are a lot of different situations with superlinear returns.', 'Superlinear returns have a lot of different situations.', 'As far as I can tell, superlinear returns reduce to two fundamental causes: exponential growth and thresholds.', 'Superlinear returns are caused by two fundamental factors: exponential growth and thresholds.', 'Exponential growth is a cause of superlinear returns.', 'Thresholds are a cause of superlinear returns.']\n",
      "========================================\n",
      "Done with 4\n"
     ]
    }
   ],
   "source": [
    "paragraphs = essay.split(\"\\n\\n\")\n",
    "len(paragraphs)\n",
    "\n",
    "#get just a couple of paragraphs\n",
    "essay_propositions = []\n",
    "\n",
    "for i, para in enumerate(paragraphs[:5]):\n",
    "    propositions = get_propositions(para)\n",
    "    \n",
    "    essay_propositions.extend(propositions)\n",
    "    print (f\"Done with {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
